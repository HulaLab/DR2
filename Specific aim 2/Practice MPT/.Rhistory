df3 %>% #removed sem_df <-
filter(ran %in% c(18, 115, 31, 168, 171, 175, 126, 47, 127, 36, 32, 123, 11, 90, 75, 71, 48, 34, 49, 60, 81,
38, 98, 29, 82, 116, 104, 28, 42, 106, 62, 163, 122, 77, 154, 70, 169, 111, 66, 8, 89, 140,
61, 170, 43, 27, 56, 114, 17, 148, 150, 151, 68, 80, 88, 2, 159, 119, 84, 173, 153, 39,
138, 137, 145, 59, 100, 54, 73, 1, 136, 19, 157, 63, 101, 40, 162, 130, 57, 117, 45, 55,
125, 64, 4, 156, 172, 79, 142, 155, 30, 52, 105, 143, 86, 58, 35, 78, 103, 108)) %>%
group_by(ability) %>%
summarize(total_info = sum(info)) %>%
mutate(SEM = (1 / (sqrt(total_info)))) %>%
mutate(upperCI = ability + 1.96 * SEM) %>%
mutate(lowerCI = ability - 1.97 * SEM)
})
sem_df175 = reactive({
df3 %>% #removed sem_df <-
filter(ran %in% c(22, 170, 31, 168, 171, 175, 126, 47, 127, 36, 32, 123, 11, 90, 75, 71, 48, 34, 49, 60, 81,
38, 98, 29, 82, 116, 104, 28, 42, 106, 62, 163, 122, 77, 154, 70, 169, 111, 66, 8, 89, 140,
61, 115, 43, 27, 56, 114, 17, 148, 150, 151, 68, 80, 88, 131, 159, 119, 84, 173, 153, 39,
138, 137, 145, 59, 100, 54, 73, 1, 136, 19, 157, 63, 101, 40, 162, 130, 57, 117, 45, 55,
125, 64, 4, 156, 172, 79, 142, 155, 30, 52, 105, 143, 86, 58, 35, 78, 103, 108, 132, 20, 5,
65, 9, 50, 141, 2, 67, 87, 46, 25, 15, 92, 96, 3, 26, 128, 158, 129, 133, 51, 91, 99, 53,
144, 83, 152, 85, 94, 23, 21, 41, 149, 72, 164, 112, 14, 93, 118, 113, 167, 24, 102, 7, 6,
44, 109, 97, 160, 134, 147, 161, 146, 37, 10, 95, 13, 110, 120, 121, 135, 16, 166, 107, 139,
165, 18, 76, 12, 124, 74, 174, 33, 69)) %>%
group_by(ability) %>%
summarize(total_info = sum(info)) %>%
mutate(SEM = (1 / (sqrt(total_info)))) %>%
mutate(upperCI = ability + 1.96 * SEM) %>%
mutate(lowerCI = ability - 1.97 * SEM)
})
output$p <- renderPlotly({
ggplot(df_react(), aes(x = ability, y = prob.correct, color = Item)) +
geom_smooth() +
#geom_point(shape=1) +
xlab("Participant naming ability") +
ylab("Probability of correct response") +
ggtitle("Item Characteristic Curves") +
theme(plot.title = element_text(hjust = 0.5))
})
output$p2.1 = renderPlotly({
ggplot(data = plot_df.1(), aes(x =ability, y= info, color = item)) + #removed
geom_line() + ylim(0, .8) +  #removed stack
xlab("Participant naming ability") +
ylab("Information") +
ggtitle("Item Information Curves") +
theme(plot.title = element_text(hjust = 0.5))
})
output$p2.2 <- renderPlotly ({
ggplot(data = plot_df.2(), aes(x = ability, y = total_info)) +
geom_line() +
xlab("Participant naming ability") +
ylab("Test Information") +
ggtitle("Test Information Curve  \nItems: Ball and Stethoscope") +
theme(plot.title = element_text(hjust = 0.5))
})
output$p2 <- renderPlotly({
a = ggplot(data = plot_df(), aes(x = ability, y = total_info)) +
geom_line() + #ylim(0, 60) +
ggtitle("Test Information Curve (Upper) Item Characteristic Curves (Lower)") +
theme(plot.title = element_text(hjust = 0.5))
a = ggplotly(a) #%>% layout(height = 1000)
b =  ggplot(data = item_df(), aes(x =ability, y= info, color = item)) +
geom_line() + #ylim(0, .8) +
theme(plot.title = element_text(hjust = 0.5)) +
theme(legend.position = "none")
subplot(a, b, nrows = 2)
})
output$p3.1 <- renderPlotly({
fig2 = plot_ly(sem_df1(), x = ~ability, y = ~SEM,  mode = 'lines',
hooverinfo = "text",
text = ~paste(
'Ability: ', ability,
'SEM: ', SEM,
'</br> Lower 95% CI: ', upperCI,
'</br> Upper 95% CI ', lowerCI))
fig1 = plot_ly(sem_df1(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 1",
yaxis = list(title = 'Information',
range =c(0, 0.5)),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
output$p3.2 <- renderPlotly({
fig2 = plot_ly(sem_df50(), x = ~ability, y = ~SEM, mode = 'lines',
hooverinfo = 'text',
text = ~paste(
'</br> Lower 95% CI: ', upperCI,
'</br> Upper 95% CI ', lowerCI)) %>%
layout(xaxis = list(showgrid = F),
yaxis = list(title = 'SEM', showgrid = F)) %>%
add_trace(name = 'SEM')
fig1 = plot_ly(sem_df50(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 50",
yaxis = list(title = 'Information'),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
output$p3.3 <- renderPlotly({
fig2 = plot_ly(sem_df100(), x = ~ability, y = ~SEM, mode = 'lines',
hooverinfo = 'text',
text = ~paste(
'</br> Lower 95% CI: ', upperCI,
'</br> Upper 95% CI ', lowerCI)) %>%
layout(xaxis = list(showgrid = F),
yaxis = list(title = 'SEM', showgrid = F),
hovermode = "x uninifed") %>%
add_trace(name = 'SEM')
fig1 = plot_ly(sem_df100(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 100",
yaxis = list(title = 'Information'),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
output$p3.4 <- renderPlotly({
fig2 = plot_ly(sem_df175(), x = ~ability, y = ~SEM, mode = 'lines') %>%
layout(xaxis = list(showgrid = F),
yaxis = list(title = 'SEM', showgrid = F) %>%
add_trace(name = 'SEM',
hovertemplate = 'SEM = %{SEM}',
'</br> Lower 95% CI: , %{lowerCI}',
'</br> Upper 95% CI: , %{upperCI}'))
fig1 = plot_ly(sem_df1(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 175",
yaxis = list(title = 'Information'),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
}
####################################################
####################################################
shinyApp(ui = ui, server = server)
library(tidyverse)
df <- tibble(
a = rnorm(100, 5, 1),
b = a + rnorm(100, 0, .5)
)
df %>%
ggplot(aes(a, b)) +
geom_point()
ggsave('plot.png', dpi = 300, height = 5, width = 5, unit = 'in')
1500/5
ggsave('plot.png', dpi = 300, height = 6, width = 6, unit = 'in')
library(brms)
warnings()
install.packages('brms')
install.packages("brms")
detach("package:brms", unload = TRUE)
install.packages("brms")
warnings()
library(readxl)
tufaq <- read_excel("C:/Users/alexa/Downloads/tufaq.xlsx",
col_types = c("text"))
View(tufaq)
library(dplyr)
tufaq$AQval = as.numeric(tufaq$AQ)
View(tufaq)
library(readxl)
tufaq <- read_excel("C:/Users/alexa/Downloads/tufaq.xlsx",
col_types = c("text"))
View(tufaq)
tufaq$AQval = as.numeric(tufaq$AQ)
summary(tufaq)
load("C:/Users/alexa/Dropbox/TUF Meta Analysis/Quique and Swiderski working R  document/ModelOutput.RData")
View(cate)
data %>% summaraize()
data %>% summarize()
odds = ln(.37)
odds = exp(.37)
odds / 1 + odds
odds = exp(.04)
odds / 1 + odds
odds / (1 + odds)
odds
setwd("C:/Users/alexa/Dropbox")
library(shiny)
library(shinydashboard)
library(shinydashboardPlus)
library(plotly)
###############data#################
#read data
library(readxl)
#mac
#hinydata <- read_excel("~/Dropbox/shinydata.xlsx")
#pc
shinydata <- read_excel("shinydata.xlsx")
data = shinydata
#create random number to randomize number of draws shown later on
set.seed(8675309)
shinydata$randomize = sample(seq(1,175, length.out = 175))
#MAKE VECTOR OF ABILITY
ability = seq(-4,4, length.out = 100)
#expand grid
item = shinydata$Item
df = expand.grid(ability, item)
library(dplyr)
runApp('Fergadiotis et al 2021 IRT ap_GF_AS.R')
shiny::runGitHub("rbcavanaugh/pnt")
remotes::install_github("rbcavanaugh/pnt")
remotes::install_github("rbcavanaugh/pnt")
library(pnt)
remove.packages("pnt")
remotes::install_github("rbcavanaugh/pnt")
library('pnt')
runPNT()
remotes::install_github("rbcavanaugh/pnt")
library(pnt)
runPNT()
setwd("C:/Users/alexa/Downloads")
data <- read.table("naveirasmd.txt",sep="\t",header=TRUE)
data <- read.table("naveirmd.txt",sep="\t",header=TRUE)
View(data)
data <- read.table("naveirmd.txt",sep=" ",header=TRUE)
?read>table
?read.table
View(data)
setwd("~/GitHub/DR2/Specific aim 2/Practice MPT")
library(readxl)
naveirmd_start_table <- read_excel("naveirmd_start_table.xlsx")
View(naveirmd_start_table)
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
View(data)
data <- <- read_excel("naveirmd_start_table.xlsx")
data <- read_excel("naveirmd_start_table.xlsx")
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
View(data)
View(data.copy)
number.of.nodes <- 1
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
View(data.node)
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
View(data.node)
View(data)
View(data.copy)
View(data.node)
View(naveirmd_start_table)
View(yy.list)
number.of.nodes <- 3
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
number.of.nodes <- 3
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
View(data.copy)
number.of.nodes <- 3
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==3){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
number.of.nodes <- 3
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==3){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
data <- <- read_excel("naveirmd_start_table.xlsx")
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
data <- read_excel("naveirmd_start_table.xlsx")
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
install.packages('mpt')
library(mpt)
citysize = citysize
citysize = citysize
citysize = data(citysize)
citysize
data(citysize)
View(WorldCities)
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
View(data.node)
data.el <- data.node[,c(1,3,4,8,9)]
names(data.el) <- variable.names <- names(data.node[,c(1,3,4,8,9)])
head(data.el)
View(data.node)
unique.trial <- sort(unique(data.el$trial))
unique.time <- sort(unique(data.el$time))
unique.node <- sort(unique(data.el$node))
number.variables <- 3
Empirical.Logit <- matrix(nrow=prod(length(unique.trial),length(unique.time),
length(unique.node)), ncol = (number.variables + 1))
Empirical.Logit <- data.frame(Empirical.Logit)
names(Empirical.Logit) <- c("trial", "time", "node", "empirical.logit")
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit < -10^6] <- -10^6
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit > 10^6] <- 10^6
row.index <- 1
for (trial in 1:length(unique.trial)){
for (time in 1:length(unique.time)){
for (node in 1:length(unique.node)){
data.el.trial.time.node <- data.el[(data.el$trial==unique.trial[trial]
& data.el$time==unique.time[time] & data.el$node==unique.node[node]),]
yy.trial.time.node <- data.el.trial.time.node$yy
proportion <- sum(yy.trial.time.node[!is.na(yy.trial.time.node)])/length(yy.trial.time.node)
empirical.logit <- log(proportion/(1 - proportion))
Empirical.Logit[row.index,] <- c(unique.trial[trial], unique.time[time],
unique.node[node], empirical.logit)
row.index <- row.index + 1
}}}
Empirical.Logit <- data.frame(Empirical.Logit)
names(Empirical.Logit) <- c("trial", "time", "node", "empirical.logit")
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit < -10^6] <- -10^6
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit > 10^6] <- 10^6
time.lag.max <- 20
time.lag.max <- 20
AC.PAC <- matrix(nrow=prod(length(unique.trial),length(unique.node),time.lag.max),
ncol=(number.variables + 2))
for (trial in 1:length(unique.trial)){
for (node in 1:length(unique.node)){
Empirical.Logit.trial.node <- Empirical.Logit[(Empirical.Logit$trial==unique.trial[trial]
& Empirical.Logit$node==unique.node[node]),]
autocorrelations <- acf(Empirical.Logit.trial.node$empirical.logit,
lag.max = time.lag.max, plot=FALSE)
autocorrelations <- autocorrelations$acf[2:(time.lag.max + 1)]
partial.autocorrelations <- pacf(Empirical.Logit.trial.node$empirical.logit,
lag.max = time.lag.max, na.action=na.pass, plot=FALSE)
partial.autocorrelations <- c(partial.autocorrelations$acf)
for (time.lag in 1:time.lag.max){
AC.PAC[(row.index + time.lag - 1),] <- c(unique.trial[trial], unique.node[node], time.lag,
autocorrelations[time.lag], partial.autocorrelations[time.lag])
}
row.index <- row.index + time.lag.max
}}
AC.PAC <- matrix(nrow=prod(length(unique.trial),length(unique.node),time.lag.max),
ncol=(number.variables + 2))
row.index <- 1
for (trial in 1:length(unique.trial)){
for (node in 1:length(unique.node)){
Empirical.Logit.trial.node <- Empirical.Logit[(Empirical.Logit$trial==unique.trial[trial]
& Empirical.Logit$node==unique.node[node]),]
autocorrelations <- acf(Empirical.Logit.trial.node$empirical.logit,
lag.max = time.lag.max, plot=FALSE)
autocorrelations <- autocorrelations$acf[2:(time.lag.max + 1)]
partial.autocorrelations <- pacf(Empirical.Logit.trial.node$empirical.logit,
lag.max = time.lag.max, na.action=na.pass, plot=FALSE)
partial.autocorrelations <- c(partial.autocorrelations$acf)
for (time.lag in 1:time.lag.max){
AC.PAC[(row.index + time.lag - 1),] <- c(unique.trial[trial], unique.node[node], time.lag,
autocorrelations[time.lag], partial.autocorrelations[time.lag])
}
row.index <- row.index + time.lag.max
}}
AC.PAC <- data.frame(AC.PAC)
names(AC.PAC) <- c("trial", "node", "time.lag", "autocorrelation", "partial.autocorrelation")
View(data.el.trial.time.node)
View(Empirical.Logit.trial.node)
View(Empirical.Logit)
View(data)
head(data.el)
# Probabilities of different answers
Pr_NR <- function(a, t, f, c)
1 - a
Pr_Neologism <- function(a, t, f, c)
a * (1 - t) * (1 - f) * (1 - c) + a * t * (1 - f) * (1 - c)
Pr_Formal <- function(a, t, f, c)
a * (1 - t) * (1 - f) * c +  a * t * (1 - f) * c
Pr_Mixed <- function(a, t, f, c)
a * (1 - t) * f
Pr_Correct <- function(a, t, f, c)
a * t * f
# true underlying values for simulated data
a_true <- .75
t_true <- .9
f_true <- .8
c_true <- .1
# Probability of the different answers:
Theta <- tibble(NR = Pr_NR(a_true, t_true, f_true, c_true),
Neologism = Pr_Neologism(a_true, t_true, f_true, c_true),
Formal = Pr_Formal(a_true, t_true, f_true, c_true),
Mixed = Pr_Mixed(a_true, t_true, f_true, c_true),
Correct = Pr_Correct(a_true, t_true, f_true, c_true))
N_trials <- 200
ans <- rmultinom(1, N_trials, c(Theta)))
(ans <- rmultinom(1, N_trials, c(Theta)))
# Probabilities of different answers
Pr_NR <- function(a, t, f, c)
1 - a
Pr_Neologism <- function(a, t, f, c)
a * (1 - t) * (1 - f) * (1 - c) + a * t * (1 - f) * (1 - c)
Pr_Formal <- function(a, t, f, c)
a * (1 - t) * (1 - f) * c +  a * t * (1 - f) * c
Pr_Mixed <- function(a, t, f, c)
a * (1 - t) * f
Pr_Correct <- function(a, t, f, c)
a * t * f
# true underlying values for simulated data
a_true <- .75
t_true <- .9
f_true <- .8
c_true <- .1
# Probability of the different answers:
Theta <- tibble(NR = Pr_NR(a_true, t_true, f_true, c_true),
Neologism = Pr_Neologism(a_true, t_true, f_true, c_true),
Formal = Pr_Formal(a_true, t_true, f_true, c_true),
Mixed = Pr_Mixed(a_true, t_true, f_true, c_true),
Correct = Pr_Correct(a_true, t_true, f_true, c_true))
N_trials <- 200
(ans <- rmultinom(1, N_trials, c(Theta)))
library(dplyr)
# Probabilities of different answers
Pr_NR <- function(a, t, f, c)
1 - a
Pr_Neologism <- function(a, t, f, c)
a * (1 - t) * (1 - f) * (1 - c) + a * t * (1 - f) * (1 - c)
Pr_Formal <- function(a, t, f, c)
a * (1 - t) * (1 - f) * c +  a * t * (1 - f) * c
Pr_Mixed <- function(a, t, f, c)
a * (1 - t) * f
Pr_Correct <- function(a, t, f, c)
a * t * f
# true underlying values for simulated data
a_true <- .75
t_true <- .9
f_true <- .8
c_true <- .1
# Probability of the different answers:
Theta <- tibble(NR = Pr_NR(a_true, t_true, f_true, c_true),
Neologism = Pr_Neologism(a_true, t_true, f_true, c_true),
Formal = Pr_Formal(a_true, t_true, f_true, c_true),
Mixed = Pr_Mixed(a_true, t_true, f_true, c_true),
Correct = Pr_Correct(a_true, t_true, f_true, c_true))
N_trials <- 200
(ans <- rmultinom(1, N_trials, c(Theta)))
# Probabilities of different answers
Pr_NR <- function(a, t, f, c)
1 - a
Pr_Neologism <- function(a, t, f, c)
a * (1 - t) * (1 - f) * (1 - c) + a * t * (1 - f) * (1 - c)
Pr_Formal <- function(a, t, f, c)
a * (1 - t) * (1 - f) * c +  a * t * (1 - f) * c
Pr_Mixed <- function(a, t, f, c)
a * (1 - t) * f
Pr_Correct <- function(a, t, f, c)
a * t * f
# true underlying values for simulated data
a_true <- .75
t_true <- .9
f_true <- .8
c_true <- .1
# Probability of the different answers:
Theta <- tibble(NR = Pr_NR(a_true, t_true, f_true, c_true),
Neologism = Pr_Neologism(a_true, t_true, f_true, c_true),
Formal = Pr_Formal(a_true, t_true, f_true, c_true),
Mixed = Pr_Mixed(a_true, t_true, f_true, c_true),
Correct = Pr_Correct(a_true, t_true, f_true, c_true))
N_trials <- 200
(ans <- rmultinom(1, N_trials, c(Theta)))
View(ans)
library(rstan)
data_sMPT <-  list(N_trials = N_trials,
ans = c(ans))
View(data_sMPT)
