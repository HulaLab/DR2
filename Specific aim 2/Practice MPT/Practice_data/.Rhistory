build an understanding of this model. The 1-PL model is expressed mathmatically below. <h4>"),
withMathJax(),
p("$$ P(x_i = 1 | \\theta_j) = \\frac{e^{\\alpha(\\theta_j - \\beta_i)}}{1+e^{\\alpha(\\theta_j - \\beta_i)}} $$"),
HTML("<h4> where the probability (P) of a correct response by examine j with a given naming ability  ?? is equal to a log transformation of the
participants naming ability minus the items difficulty (?? - ??).  Note that ?? is the item discriminitation parameter, which is
assumed to be equal for all items.Item difficulty can be conceptualized as the relative ease or
challenge of producing a correct response on a given item. In the examples to come, difficulty reflects the challenge assosciated with producing a correct response on a given picure on the PNT.  Ability is the degree to which an
individual possesses a given skill or attribute. For the purpose of this tutorial,  ability and any numerical estimates associated with it will refer
to the degree of naming impairment, or anomia severity. Once an item has been calibrated using IRT methods (e.g., Fergadiotis, Hula, & Kellough, 2015) sigmoid curves can
be utilized to predict the probability of a correct response for patients with different levels of ability.
These curves are called <b>Item Characteristic Curves</b>, or ICCs. Further information about ICCs and graphical models of their sigmoid curves can be found
by navigating to the Item Characteristic Curve tab, on the left side of this screen. <h4>")
) #end column
) # end fluidrow
), #end tabItem = Welcome
tabItem(
tabName = "ICC",
h1("Item Characteristic Curves"),
fluidRow(
column(
width = 10,
HTML("<h4> The interactive figure below shows Item Characteristic Curves for three items from the PNT: ball, ambulance, and microscope.
You may add and remove items by clicking the text box where ball, ambulance, and microscope are displayed. Ability is plotted on
the x axis ranging -4 to 4.  It is important to note that a zero-ability estimate does not represent no naming ability, but the mean
naming ability. Therefore, this scale reflects the lowest plotted naming ability estimate of -4 and the highest naming ability estimate of 4,
and all potential naming abilities between -4 and 4.  The y axis represents the probability of a given individual with a naming ability of
THETA.  The probability of correct responses are estimated with the 1-PL model as previously presented, but also provided below for
convenience.  <h4>"),
withMathJax(),
p("$$ P(x_i = 1 | \\theta_j) = \\frac{e^{\\alpha(\\theta_j - \\beta_i)}}{1+e^{\\alpha(\\theta_j - \\beta_i)}} $$"),
HTML("<h4> For ease of plot interpretation we suggest hovering your mouse over the figure until a series of buttons overlay the top
right corner of the figure and selecting <em> Toggle Spike Lines </em>.  By scrolling over each curve the probability of a correct response
can be easily seen, which was estimated using the 1-PL model.  For example, an individual with a naming ability of 0 has a probability
of responding correctly to ball of 0.80, where as the nave a probability of responding to ambulance and microscope of P = 0.33 and P  = 0.05.
Note that the probability of correct response varies for each item based on the participants ability and the items difficulty."),
selectInput(
inputId = "Item",
label = "Select an item",
choices = unique(df2$Item),
selected = c("ball","ambulance", "microscope"),
multiple = TRUE
),
plotlyOutput(outputId = "p"),
h1("Computer Adaptive Testing"),
HTML("<h4> ICCs clearly present a strength of computer adaptive testing.  That is, they clearly present how some items may be provide
little to no information regarding a participant's naming ability.  For Example, should a participant have a naming ability ranging from
-4 through 2 they have a very small chance of responding correctly to items such as  <em> microscope </em> or <em>stethoscope</em>. The clinician in
this setting would yield very little information that they did not already know.  That is, the participant has severe naming deficits and
is therefore unlikely to name difficult words correctly.  Furthermore, by providing these items may increase testing burden on these individuals.
It is clear when you select easier items such as <em> ball, cat</em>, and <em> dog</em> that individuals that fall within this naming ability range have a far
greater probability of responding correctly to these items.  <h4>"),
HTML("<h4>However, as can be seen by the ICCs for these items, these participants do not
have a 100% chance of responding correctly to this item.  Not delivering items that are too easy for the participant is of equal importance
as delivering items that are far too hard.  Why?  Because a clinician gains limited, if not no, information about the participants naming
impairment by delivering items that the individual responds correctly to 100% of the time.  Consider the participant with a naming ability of 3.
According to the ICCs they have 100% chance of responding correctly to the items <em> ball, dog </em>, and <em> cat </em>.  However, when the items ambulance,
microscope, and stethoscope are delivered they are expected to longer perform at ceiling.  Here we have provided two examples of the need to select
items based on a participant's naming ability to better understand their naming impairment.  In the following section, <b> Test Information Curves </b>
we further the relationship between the items estimated difficulty and the amount of information it may provide on a given participants naming ability.
Then, we sum this information to show how increasing the number of items increases the amount of information a clinician can learn about an individual's
naming severity. <h4>")
), #end column
) #end fluid row
),
tabItem(
h1("Information Curves"),
tabName = "TCC",
fluidRow(
column(
width = 10,
HTML("<h4> In statistics, Fisher information, hence fourth refered to as information can be interpretted as the amount of information
that an observed variable carries about an unknown or latent variable.  As it pertains picture naming and anomia, the amount of information
a clincician can learn of an individuals anomia severity varies based on the individual item administered or a group of items administed. At this point you may be wondering,
why might one picture have more or less information than another? Simply stated, two items may have equal information, but provide more information than one another based on a participants ability.
Piggybacking on the previous example provided in the previous section, the item <em> stethescope </em> may provide more information as to the severity of naming impairment for a participant
with a relatively high naming ability, where as this item provides little information for individuals with a servere naming impairment. Conversly, ball provides little information on the naming impairment of a very mild
naming severity where as it provides more information as to the severity of impairment for an individual with a more severe impairment.  This is depicted in the first figure below.  Note, that the area under the curve
for <em> stethescope </em> is greater over ability estimates reflecting mild naming impairments whereas the majority of the distribution of for item information function for <em> ball </em> is above much lower
naming impairments.
"),
plotlyOutput(outputId = "p2.1"),
HTML("<h4> To estiamte a tests information, we simply sum the item information curves.  Presented below is the test information curve for a testing instrument that includes
only the two items <em> ball </em> and <em> stethoscope </em>. Note that the apex of the Test Information Curve is the sum of upper tail of the ICC for <em> ball </em>and the lower tail of the ICC for <em> stethoscope. </em> <h4>"),
plotlyOutput(outputId = "p2.2"),
HTML("<h4> To demonstrate the cumulative effects off increasing the number of items on the total test information, we present the Test and Item information curvse below. Note, that the top curve is the test information curve
and the lower panel includes the item information curves. The y axis for the test information curve if fixed with a range of 0 through 60.  Note that the previous test information curve presented above
does not exceed an information estimate of 1. For this reason, when the scroller bar is set to one the test information does not match the item information curve, because of the fixed scale.
However, as the number of items is increased, the overall test information can be observed increase until all of the items of the Philadelphia Naming Test have been added."),
sliderInput('NumberofWords', "Number of Words",
min = 1, max = 175, value = min(df3$ran)),
plotlyOutput(outputId = "p2")
), #end column
), # end fluid row for TCC
), # End tabItem for TCC
tabItem(
tabName = "SEM",
h1("Standard Error of Measurement"),
fluidRow(
column(
width = 10,
HTML("<h4> Standard Error of Measurment (SEM) is a statistic aimed at estimating test re-test performance of participants.  Specifically,
aims to estimate the ability of a participant on the same test, in which they have previously taken. Indeed, for a testing instrument
to be clinically useful, it needs to elicit consistent results in the abscence of clinical changes. In classical test theory, where all items
are assumed to provide equal information, the SEM is assumed to be equal across the testing insturment. Standard error of the estimate (SEE) is analagous
to SEM, in the IRT framework. However, SEE has a distinct advantage over SEM, as SEE can be estimated across item difficulties and person abilities. This is because Standard Error Estimate is
the reciprocal of the Item Information Function. and is estimated as follows: <h4>"),
#withMathJax(),
#helptext("$$ SEE(\\theta) = \\frac{1}{\\sqrt{I(\\theta)} $$")
plotlyOutput(outputId = "p3.1"),
plotlyOutput(outputId = "p3.2"),
plotlyOutput(outputId = "p3.3"),
plotlyOutput(outputId = "p3.4")
), #end column
) # End fluid row for SEM
) # End tabitem for SEM
) #end TabItems
) #end dashboard body
)
#Create server:
server <- function(input, output, ...) {
df_react <- reactive({
df2 %>%
filter(Item %in% input$Item)
})
plot_df.1 =  reactive({
df3 %>% mutate(ability = round(ability, 2)) %>%#,
#info = info*input$NumberofWords)
filter(item %in% c("ball", "stethoscope"))
})
plot_df.2 = reactive({
df3 %>%
mutate(ability = round(ability, 2)) %>%#,
#info = info*input$NumberofWords)
filter(item %in% c("ball", "stethoscope")) %>%
group_by(ability) %>%
summarize(total_info = sum(info))
})
plot_df <- reactive({
df3 %>% #removed plot_df <-
mutate(ability = round(ability, 2)) %>%
filter(ran <= input$NumberofWords) %>%
group_by(ability) %>%
summarize(total_info = sum(info))
})
item_df <- reactive({
df3 %>%
mutate(ability = round(ability, 2)) %>%#,
#info = info*input$NumberofWords)
filter(ran <= input$NumberofWords)
})
sem_df1 = reactive({
df3 %>% #removed sem_df <-
filter(ran %in% c(18)) %>%
group_by(ability) %>%
summarize(total_info = sum(info)) %>%
mutate(SEM = (1 / (sqrt(total_info)))) %>%
mutate(upperCI = ability + 1.96 * SEM) %>%
mutate(lowerCI = ability - 1.97 * SEM)
})
sem_df50 = reactive({
df3 %>% #removed sem_df <-
filter(ran %in% c(18, 115, 31, 168, 171, 175, 126, 47, 127, 36, 32, 123, 11, 90, 75, 71, 48, 34, 49, 60, 81,
38, 98, 29, 82, 116, 104, 28, 42, 106, 62, 163, 122, 77, 154, 70, 169, 111, 66, 8, 89, 140,
61, 170, 43, 27, 56, 114, 17, 148)) %>%
group_by(ability) %>%
summarize(total_info = sum(info)) %>%
mutate(SEM = (1 / (sqrt(total_info)))) %>%
mutate(upperCI = ability + 1.96 * SEM) %>%
mutate(lowerCI = ability - 1.97 * SEM)
})
sem_df100 = reactive({
df3 %>% #removed sem_df <-
filter(ran %in% c(18, 115, 31, 168, 171, 175, 126, 47, 127, 36, 32, 123, 11, 90, 75, 71, 48, 34, 49, 60, 81,
38, 98, 29, 82, 116, 104, 28, 42, 106, 62, 163, 122, 77, 154, 70, 169, 111, 66, 8, 89, 140,
61, 170, 43, 27, 56, 114, 17, 148, 150, 151, 68, 80, 88, 2, 159, 119, 84, 173, 153, 39,
138, 137, 145, 59, 100, 54, 73, 1, 136, 19, 157, 63, 101, 40, 162, 130, 57, 117, 45, 55,
125, 64, 4, 156, 172, 79, 142, 155, 30, 52, 105, 143, 86, 58, 35, 78, 103, 108)) %>%
group_by(ability) %>%
summarize(total_info = sum(info)) %>%
mutate(SEM = (1 / (sqrt(total_info)))) %>%
mutate(upperCI = ability + 1.96 * SEM) %>%
mutate(lowerCI = ability - 1.97 * SEM)
})
sem_df175 = reactive({
df3 %>% #removed sem_df <-
filter(ran %in% c(22, 170, 31, 168, 171, 175, 126, 47, 127, 36, 32, 123, 11, 90, 75, 71, 48, 34, 49, 60, 81,
38, 98, 29, 82, 116, 104, 28, 42, 106, 62, 163, 122, 77, 154, 70, 169, 111, 66, 8, 89, 140,
61, 115, 43, 27, 56, 114, 17, 148, 150, 151, 68, 80, 88, 131, 159, 119, 84, 173, 153, 39,
138, 137, 145, 59, 100, 54, 73, 1, 136, 19, 157, 63, 101, 40, 162, 130, 57, 117, 45, 55,
125, 64, 4, 156, 172, 79, 142, 155, 30, 52, 105, 143, 86, 58, 35, 78, 103, 108, 132, 20, 5,
65, 9, 50, 141, 2, 67, 87, 46, 25, 15, 92, 96, 3, 26, 128, 158, 129, 133, 51, 91, 99, 53,
144, 83, 152, 85, 94, 23, 21, 41, 149, 72, 164, 112, 14, 93, 118, 113, 167, 24, 102, 7, 6,
44, 109, 97, 160, 134, 147, 161, 146, 37, 10, 95, 13, 110, 120, 121, 135, 16, 166, 107, 139,
165, 18, 76, 12, 124, 74, 174, 33, 69)) %>%
group_by(ability) %>%
summarize(total_info = sum(info)) %>%
mutate(SEM = (1 / (sqrt(total_info)))) %>%
mutate(upperCI = ability + 1.96 * SEM) %>%
mutate(lowerCI = ability - 1.97 * SEM)
})
output$p <- renderPlotly({
ggplot(df_react(), aes(x = ability, y = prob.correct, color = Item)) +
geom_smooth() +
#geom_point(shape=1) +
xlab("Participant naming ability") +
ylab("Probability of correct response") +
ggtitle("Item Characteristic Curves") +
theme(plot.title = element_text(hjust = 0.5))
})
output$p2.1 = renderPlotly({
ggplot(data = plot_df.1(), aes(x =ability, y= info, color = item)) + #removed
geom_line() + ylim(0, .8) +  #removed stack
xlab("Participant naming ability") +
ylab("Information") +
ggtitle("Item Information Curves") +
theme(plot.title = element_text(hjust = 0.5))
})
output$p2.2 <- renderPlotly ({
ggplot(data = plot_df.2(), aes(x = ability, y = total_info)) +
geom_line() +
xlab("Participant naming ability") +
ylab("Test Information") +
ggtitle("Test Information Curve  \nItems: Ball and Stethoscope") +
theme(plot.title = element_text(hjust = 0.5))
})
output$p2 <- renderPlotly({
a = ggplot(data = plot_df(), aes(x = ability, y = total_info)) +
geom_line() + #ylim(0, 60) +
ggtitle("Test Information Curve (Upper) Item Characteristic Curves (Lower)") +
theme(plot.title = element_text(hjust = 0.5))
a = ggplotly(a) #%>% layout(height = 1000)
b =  ggplot(data = item_df(), aes(x =ability, y= info, color = item)) +
geom_line() + #ylim(0, .8) +
theme(plot.title = element_text(hjust = 0.5)) +
theme(legend.position = "none")
subplot(a, b, nrows = 2)
})
output$p3.1 <- renderPlotly({
fig2 = plot_ly(sem_df1(), x = ~ability, y = ~SEM,  mode = 'lines',
hooverinfo = "text",
text = ~paste(
'Ability: ', ability,
'SEM: ', SEM,
'</br> Lower 95% CI: ', upperCI,
'</br> Upper 95% CI ', lowerCI))
fig1 = plot_ly(sem_df1(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 1",
yaxis = list(title = 'Information',
range =c(0, 0.5)),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
output$p3.2 <- renderPlotly({
fig2 = plot_ly(sem_df50(), x = ~ability, y = ~SEM, mode = 'lines',
hooverinfo = 'text',
text = ~paste(
'</br> Lower 95% CI: ', upperCI,
'</br> Upper 95% CI ', lowerCI)) %>%
layout(xaxis = list(showgrid = F),
yaxis = list(title = 'SEM', showgrid = F)) %>%
add_trace(name = 'SEM')
fig1 = plot_ly(sem_df50(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 50",
yaxis = list(title = 'Information'),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
output$p3.3 <- renderPlotly({
fig2 = plot_ly(sem_df100(), x = ~ability, y = ~SEM, mode = 'lines',
hooverinfo = 'text',
text = ~paste(
'</br> Lower 95% CI: ', upperCI,
'</br> Upper 95% CI ', lowerCI)) %>%
layout(xaxis = list(showgrid = F),
yaxis = list(title = 'SEM', showgrid = F),
hovermode = "x uninifed") %>%
add_trace(name = 'SEM')
fig1 = plot_ly(sem_df100(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 100",
yaxis = list(title = 'Information'),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
output$p3.4 <- renderPlotly({
fig2 = plot_ly(sem_df175(), x = ~ability, y = ~SEM, mode = 'lines') %>%
layout(xaxis = list(showgrid = F),
yaxis = list(title = 'SEM', showgrid = F) %>%
add_trace(name = 'SEM',
hovertemplate = 'SEM = %{SEM}',
'</br> Lower 95% CI: , %{lowerCI}',
'</br> Upper 95% CI: , %{upperCI}'))
fig1 = plot_ly(sem_df1(), x = ~ability, y = ~total_info, mode = 'lines')
fig1 = fig1 %>%layout(title = "Test Information Function (Upper); SEM (Lower) <br> n = 175",
yaxis = list(title = 'Information'),
xaxis = list(title = "Ability")) %>%
add_trace(name = 'Test Information')
subplot(fig1, fig2, nrows = 2)
})
}
####################################################
####################################################
shinyApp(ui = ui, server = server)
library(tidyverse)
df <- tibble(
a = rnorm(100, 5, 1),
b = a + rnorm(100, 0, .5)
)
df %>%
ggplot(aes(a, b)) +
geom_point()
ggsave('plot.png', dpi = 300, height = 5, width = 5, unit = 'in')
1500/5
ggsave('plot.png', dpi = 300, height = 6, width = 6, unit = 'in')
library(brms)
warnings()
install.packages('brms')
install.packages("brms")
detach("package:brms", unload = TRUE)
install.packages("brms")
warnings()
library(readxl)
tufaq <- read_excel("C:/Users/alexa/Downloads/tufaq.xlsx",
col_types = c("text"))
View(tufaq)
library(dplyr)
tufaq$AQval = as.numeric(tufaq$AQ)
View(tufaq)
library(readxl)
tufaq <- read_excel("C:/Users/alexa/Downloads/tufaq.xlsx",
col_types = c("text"))
View(tufaq)
tufaq$AQval = as.numeric(tufaq$AQ)
summary(tufaq)
load("C:/Users/alexa/Dropbox/TUF Meta Analysis/Quique and Swiderski working R  document/ModelOutput.RData")
View(cate)
data %>% summaraize()
data %>% summarize()
odds = ln(.37)
odds = exp(.37)
odds / 1 + odds
odds = exp(.04)
odds / 1 + odds
odds / (1 + odds)
odds
setwd("C:/Users/alexa/Dropbox")
library(shiny)
library(shinydashboard)
library(shinydashboardPlus)
library(plotly)
###############data#################
#read data
library(readxl)
#mac
#hinydata <- read_excel("~/Dropbox/shinydata.xlsx")
#pc
shinydata <- read_excel("shinydata.xlsx")
data = shinydata
#create random number to randomize number of draws shown later on
set.seed(8675309)
shinydata$randomize = sample(seq(1,175, length.out = 175))
#MAKE VECTOR OF ABILITY
ability = seq(-4,4, length.out = 100)
#expand grid
item = shinydata$Item
df = expand.grid(ability, item)
library(dplyr)
runApp('Fergadiotis et al 2021 IRT ap_GF_AS.R')
shiny::runGitHub("rbcavanaugh/pnt")
remotes::install_github("rbcavanaugh/pnt")
remotes::install_github("rbcavanaugh/pnt")
library(pnt)
remove.packages("pnt")
remotes::install_github("rbcavanaugh/pnt")
library('pnt')
runPNT()
remotes::install_github("rbcavanaugh/pnt")
library(pnt)
runPNT()
setwd("~/GitHub/DR2/Specific aim 2/Practice MPT/Practice_data")
library(dplyr)
library(readxl)
naveirmd_start_table <- read_excel("~/GitHub/DR2/Specific aim 2/Practice MPT/naveirmd_start_table.xlsx")
View(naveirmd_start_table)
setwd("~/GitHub/DR2/Specific aim 2/Practice MPT/Practice_data")
library(dplyr)
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
data.el <- data.node[,c(1,3,4,8,9)]
names(data.el) <- variable.names <- names(data.node[,c(1,3,4,8,9)])
head(data.el)
unique.trial <- sort(unique(data.el$trial))
unique.time <- sort(unique(data.el$time))
unique.node <- sort(unique(data.el$node))
number.variables <- 3
Empirical.Logit <- matrix(nrow=prod(length(unique.trial),length(unique.time),
length(unique.node)), ncol = (number.variables + 1))
row.index <- 1
for (trial in 1:length(unique.trial)){
for (time in 1:length(unique.time)){
for (node in 1:length(unique.node)){
data.el.trial.time.node <- data.el[(data.el$trial==unique.trial[trial]
& data.el$time==unique.time[time] & data.el$node==unique.node[node]),]
yy.trial.time.node <- data.el.trial.time.node$yy
proportion <- sum(yy.trial.time.node[!is.na(yy.trial.time.node)])/length(yy.trial.time.node)
empirical.logit <- log(proportion/(1 - proportion))
Empirical.Logit[row.index,] <- c(unique.trial[trial], unique.time[time],
unique.node[node], empirical.logit)
row.index <- row.index + 1
}}}
Empirical.Logit <- data.frame(Empirical.Logit)
names(Empirical.Logit) <- c("trial", "time", "node", "empirical.logit")
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit < -10^6] <- -10^6
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit > 10^6] <- 10^6
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
data = naveirmd_start_table
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
data.el <- data.node[,c(1,3,4,8,9)]
names(data.el) <- variable.names <- names(data.node[,c(1,3,4,8,9)])
head(data.el)
unique.trial <- sort(unique(data.el$trial))
unique.time <- sort(unique(data.el$time))
unique.node <- sort(unique(data.el$node))
number.variables <- 3
Empirical.Logit <- matrix(nrow=prod(length(unique.trial),length(unique.time),
length(unique.node)), ncol = (number.variables + 1))
row.index <- 1
for (trial in 1:length(unique.trial)){
for (time in 1:length(unique.time)){
for (node in 1:length(unique.node)){
data.el.trial.time.node <- data.el[(data.el$trial==unique.trial[trial]
& data.el$time==unique.time[time] & data.el$node==unique.node[node]),]
yy.trial.time.node <- data.el.trial.time.node$yy
proportion <- sum(yy.trial.time.node[!is.na(yy.trial.time.node)])/length(yy.trial.time.node)
empirical.logit <- log(proportion/(1 - proportion))
Empirical.Logit[row.index,] <- c(unique.trial[trial], unique.time[time],
unique.node[node], empirical.logit)
row.index <- row.index + 1
}}}
Empirical.Logit <- data.frame(Empirical.Logit)
names(Empirical.Logit) <- c("trial", "time", "node", "empirical.logit")
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit < -10^6] <- -10^6
Empirical.Logit$empirical.logit[Empirical.Logit$empirical.logit > 10^6] <- 10^6
head(data)
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
library(dplyr)
data = naveirmd_start_table
head(data)
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
setwd("~/GitHub/DR2/Specific aim 2/Practice MPT/Practice_data")
library(readxl)
naveirmd_start_table <- read_excel("~/GitHub/DR2/Specific aim 2/Practice MPT/naveirmd_start_table.xlsx")
View(naveirmd_start_table)
data = naveirmd_start_table
head(data)
number.of.nodes <- 2
for (node in 1:number.of.nodes){
data.copy <- data
data.copy$node <- rep(node, nrow(data))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}
yy.list <- list(list(1,1,0),list(1,0,NA))
for (observation in 1:nrow(data.node)){
data.node$yy[observation] <- yy.list[[data.node$node[observation]]][[data.node$y[observation]]]
}
View(data.node)
