---
title: 'Preliminary investigations of visual world paradigm data: Dynamic GLMs and
  Dynamic Tree-Based Item Response Models'
author: "AMS"
date: "12/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r}
library(dplyr)
library(ggplot2)
library(lme4)
library(readxl)
library(dagitty)
#install.packages('ggdag')
library(ggdag)
library(data.tree)
```

### Loading Data

When the data is extracted from the edf file it was in a old excel form that neither my computer or R liked. I opened and saved it as a newer version of an excel workbook, though a csv file would work too.It would be worthwhile to double check to see if this excel file looks correct.

```{r}
library(readxl)
Practice_xls <- read_excel("Participant2.xlsx") %>% 
  filter(condition != "practice")
```

# Right_IA_0\_sample count is supposed to index the participant not looking at any of the targets. We get values \$ 1-10 \$. Removing all of the values greater than 0 for the time being, but we should address this.

```{r}
df = Practice_xls %>%
  filter(RIGHT_IA_0_SAMPLE_COUNT < 1)
```

# Directed Acyclic Graphs

## Need to think about The flow of expected cognitive properties. Consider Figures below. Does the expected eye track always match the hypothesized cognitive process order?

```{r}
#Create tree structure
TreeStructure = Node$new("Phonological Input: y*tlji1")
UnrelComp = TreeStructure$AddChild("Unrelated Competitor (ytlji = 4)")
PhonProcessing = TreeStructure$AddChild("Phonological Processing (y*tlji2)")
TreeStructure$AddChildNode(PhonProcessing)
PhonComp = PhonProcessing$AddChild("Phonological Competitor (ytlji = 3)")
SemProcessing = PhonProcessing$AddChild("Semantic Processing (y*tlji3)")
PhonProcessing$AddChildNode(SemProcessing)
SemComp = SemProcessing$AddChild("Semantic Competitor (ytlji = 2)")
Target = SemProcessing$AddChild("Target (ytlji = 1)")

#Add Probabilities 


print(TreeStructure, "p")
Do(TreeStructure$leaves, function(node) SetNodeStyle(node, shape = "rectangle"))
plot(TreeStructure)
```

## Create data frame equal to Table 1 in Neivera et al. We do NOT have a y variable so I am going to try and make it. This should be double checked by the team.

```{r}
df2 = df %>%
  rename(aoi1 = RIGHT_IA_1_SAMPLE_COUNT) %>%
  rename(aoi2 = RIGHT_IA_2_SAMPLE_COUNT) %>%
  rename(aoi3 = RIGHT_IA_3_SAMPLE_COUNT) %>%
  rename(aoi4 = RIGHT_IA_4_SAMPLE_COUNT)

#Following schmit et al, change all values below 5ms to 0 and above to 10 (pg 14, table expalnation.
df2$aoi1 = ifelse(df2$aoi1 < 5, 10, 0)
df2$aoi2 = ifelse(df2$aoi2 < 5, 10, 0)
df2$aoi3 = ifelse(df2$aoi3 < 5, 10, 0)
df2$aoi4 = ifelse(df2$aoi4  < 5, 10, 0)

#create single column showing what aoi participant was looking at
df2$aoi_all = ifelse(df2$aoi1 > 0, 1,
              ifelse(df2$aoi2 > 0, 2, 
                     ifelse(df2$aoi3 > 0, 3,
                            ifelse(df2$aoi4 > 0,4, 0))))

df2$y_5 = ifelse(df2$aoi_all == df2$unrelated_location, 4,
               ifelse(df2$aoi_all == df2$phonemic_location, 3,
                      ifelse(df2$aoi_all == df2$semantic_location, 2,
                             ifelse(df2$aoi_all == df2$target_location, 1, 0)))) 
# yy.list is the hierachical structure of available steps in the tree model. 

library(tidyr)

df2 = df2 %>%
  mutate(y =  na_if(y_5, 0)) %>% 
  fill(y, .direction = "up")

df3 = data.frame(  
  trial = df2$TRIAL_INDEX,
  person = rep(2, nrow(df2)),
  time = df2$BIN_START_TIME,
  item = df2$targetword,
  y = df2$y
)

#Sanity check make sure we did the missing data transformation correct
#does step 1 result in missing data in the form of numerical value 0? (yes)
unique(df2$aoi_all)
#Does step 2 result in missing data in the form of numerical value 0? (yes)
unique(df2$y_5)
#does step 3 remove na in the form of zero and replace with nedxt highest number in teh sequence? (yes)
NA_check = data.frame(df2$y_5, df3$y)

#Duplicate data for the number of nodes

number.of.nodes <- 3
for (node in 1:number.of.nodes){
data.copy <- df3
data.copy$node <- rep(node, nrow(df3))
if (node==1){data.node <- data.copy} else {data.node <- rbind(data.node,data.copy)}
}

```

## Now we have Table 2 completed from Schmidt et al (page 21). Note that y in the r document is equal to $y_{tlji}$ in table 2

![YY variable figures](Table%20yy.png)

\#Duplicate data for number of nodes where \$ n = 3 \$ creates the new data frame with the inclusion of the node variable, first by copying the data for each node and then combining the copies into a single data frame. Note that the number of rows for `data.node [nrow(data.node)]` should be equal to \$ number.of.nodes×nrow(data)\$

```{r}
data.node$yy = ifelse(data.node$node== 1 & data.node$y == 1, 1, #node 1 and correct
                      ifelse(data.node$node== 1 & data.node$y == 2, 1, #node 2 and semantic comp
                             ifelse(data.node$node== 1 & data.node$y == 3, 1, #node 3 and phonological comp
                                    ifelse(data.node$node== 1 & data.node$y == 4, 0, #node 4 and unrelated comp
              ifelse(data.node$node== 2 & data.node$y == 1, 1, #node 1 and correct
                      ifelse(data.node$node== 2 & data.node$y == 2, 1, #node 2 and semantic comp
                             ifelse(data.node$node== 2 & data.node$y == 3, 0, #node 3 and phonological comp
                                    ifelse(data.node$node== 2 & data.node$y == 4, NA,  #node 4 and unrelated comp
              ifelse(data.node$node== 3 & data.node$y == 1, 1, #node 1 and correct
                      ifelse(data.node$node== 3 & data.node$y == 2, 0, #node 2 and semantic comp
                             ifelse(data.node$node== 3 & data.node$y == 3, NA, #node 3 and phonological comp
                                    ifelse(data.node$node== 3 & data.node$y == 4, NA, -999#node 4 and unrelated comp
                                           ))))))))))))
```

### Sanity check, does yy contain any values other than 1,0, or NA. No.

```{r}
unique(data.node$yy)
```

\#Calculate empirical logit First, create data.el, as done by naveirmd.github.io...

```{r}
data.el = data.frame(
  trial = data.node$trial,
  person = data.node$person,
  time = data.node$time,
  node = data.node$node,
  yy = data.node$yy
)
head(data.el)
```

\#Assign unique values for trial, time, and node.

`number.variables` is the number of variables used to estimate the $empirical.logit$

$Empirical.Logit$ is a matrix with each row having unique combinations of $trial$, $time$, and $node$


\#Estimate Empirical Logits Line 1 in the code above simply sets the initial value for the $row.index$ we'll use to specify what row of $Empirical.Logit$ we're currently using. Lines 3-5 indicate that we're repeating the following process for each unique combination of $trial$, $time$, and $node$. Line 7 extracts the rows of $data.el$ that match the unique combination of $trial$, $node$, and $time$ we're calculating the empirical logit for, calling this variable $data.el.trial.time.node.$ Line 9 extracts the values for $yy$ from $data.el.trial.time.node$, which will be used to calculate the empirical logit. Lines 10-11 calculate the empirical logit, using the formula `empirical.logit=log(proportion1−proportion)`, where the proportion is the proportion of $yy.trial.time.node$ equal to one $(∑yylength(yy))$. Lines 17-18 turn Empirical.Logit into a dataframe, with the appropriate names for its variables. Lines 19-20 deal with any cases where $empirical.logit=±∞$, which can occur when proportion=0 or proportion=1. Because the autocorrelations and partial autocorrelations cannot be calculated with infinite empirical logits, we set these values to extremely large values in magnitude (in this case, ±106).

\$\$ elog = log\left(\frac{Y + .5}{N - Y + .5}\right) \\

Y = probability of yy at node  at node i \\ N = total number of observations of yy at node i \$\$

Y = probability of yy at node at node i

N = total number of observations of yy at node i

Looking at Empirical.Logit, we should now have the calculated values for empirical logit:

```{r}
library(dplyr)
EL2 = data.el %>%
  group_by(node, trial, person) %>%
  na.omit() %>%
  mutate(rep1 = rep(1)) %>%
  mutate(n_yy = sum(yy))
  
EL3 = data.el %>%
  group_by(trial, node) %>%
  mutate(cum_sum =cumsum(rep1)) %>%
  mutate(el = log((estimate +.5)/((cum_sum - estimate)+5)))
mutate(prop_yy = n_yy/n_obs) %>%
  select(time, person, trial, yy, node, n_yy, n_obs, prop_yy, rep1)


Empirical.Logit = data.frame(
    trial = as.factor(EL2$trial),
    time = as.numeric(EL2$time),
    node = as.factor(EL2$node),
    person = as.numeric(EL2$person),
    estimate = log(EL2$prop_yy + 0.5) / ((EL2$n_obs - EL2$n_yy) + 0.5))

unique(Empirical.Logit$estimate)
```

### Calculate autocorrelation and Partial Autocorrelations

```{r}
top_500 <- Empirical.Logit[1:501,]
#Autocorrelation 
#Empirical.Logit$trial = Empirical.Logit$trial - 6
ac_df = top_500 %>%
  arrange(node, trial, time) %>%
  group_by(node, trial, person) %>%
  mutate(n=1,
         obs_tnp = cumsum(n)) %>%
  mutate(ac_list = list(acf(estimate, lag.max = 20))) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(autocorrelation = ac_list$acf[obs_tnp])
  

ac_pc = ac_df %>%
  arrange(person, node, trial, time) %>%
  group_by(node, trial, person) %>%
  mutate(n=1,
         obs_tnp = cumsum(n)) %>%
  mutate(ac = list(pcf(estimate, lag.max = 20))) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(ac2 = ac$acf[obs_tnp])
```
